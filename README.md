# ðŸ“Ÿ Local LLM Chat

iOS chat app with **Llama 3.2 1B running locally** (no internet).

## âœ¨ Features

- Single chat thread
- Streaming responses
- Customizable system prompt
- Model auto-download (~700 MB)

## ðŸ› ï¸ Stack

- **UI:** SwiftUI (iOS 17+)
- **LLM:** MLX + Llama 3.2 1B (4-bit quantized)
- **Data:** SwiftData
- **Testing:** Swift Testing (TDD approach)

## ðŸ“ Architecture

```
Message (SwiftData) â”€â”€> ChatViewModel â”€â”€> ChatView
                              â†“
                       LLMEvaluator (MLX)
```

---

Inspired by [Fullmoon](https://github.com/mainframecomputer/fullmoon-ios)
